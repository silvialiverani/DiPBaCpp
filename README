########## DiPBaC++: C++ and R code version 1.1.0 ##################

### Author ###
David Hastie, Imperial College London


### Description ###
Program to implement Dirichlet Process Bayesian Clustering as described in 
Hastie et al. 2011. Previously this project was called profile regression.

   - Implements an infinite Dirichlet process model
   - Handles categorical, ordinal or normal covariates
   - Handles Bernoulli, Binomial or Poisson responses
   - Handles Extra Variation in the response 
   - Handles variable selection (tested in Discrete covariate case only)
   - Includes label switching moves for better mixing
   - Allows user to exclude the response from the model
   - Allows users to run predictive scenarios (at C++ run time)
   - Basic or Rao-Blackwellised predictions can be produced	
   - Handling of missing data
   - C++ for model fitting
   - Uses Armadillo compiled against Goto blas
   - Adaptive MCMC where appropriate
   - R package for generating simulate data and post processing
   - R plotting functions allow user choice of what to order clusters by
   - R Functionality for comparison of profile runs


### ChangeLog: ###
This is the first major version of the this software, but the software
was previously available from the author in the profileRegression archive
Changes since profileRegression version 2.0.1
   - Changes to this README, in particular noting that it was --fixedAlloc not 
     --fixedInit run time option that was removed in version 2.0.0, and 
     correction of arguments to the discussion of R calcPredictions function. 
   - Changes to R package to correct warnings from calcOptimalClustering not 
     closing files, if maxNClusters argument was not null, and to remove unused 
     argument to R calcPredictions function.
   - Fixed bugs in the C++ for implementation of variable selection for Normal 
     covariates
Changes since DiPBaCpp 1.0.0
   - Added calculation of log odds ratio into predictions
   - Hot fixed a bug with the R package where the C++ being called for 
     computing the dissimilarity matrix was calling the wrong package.
   	
### Known bugs and issues: ###
   - Variable selection for Normal covariates is only partially tested. C++ seems
     to behave well, but have not looked at post processing.


### Dependencies: ###
The following are packages and libraries are required
   - Boost header libraries (http://www.boost.org)
   - Goto blas
   - Armadillo (http://arma.sourceforge.net/) compiled against Goto blas
   - cmake

### Installation: ###
To install the program you need the free "cmake" build utility.

In the main directory type 
>cmake .

Then
>make

This will create the executable in the bin subdirectory.


### Input Data: ###
Before the program can be run the data must be formatted in the expected way. 
The input file is made up of the
   -No of subjects
   -No of covariates
   -Covariate names (1 per line)
   -No of confounders
   -Confounder names (1 per line, only if the no. of confounders > 0)
   -Number of categories per covariate (only if the covariates are discrete, 
    i.e. categorical or ordinal)
   -Binary indicator of whether or not the covariates are ordinal (only if the 
    covariates are discrete, i.e. categorical or ordinal)
   -Data

Each line of the data corresponds to a separate subject and for each subject 
should be in the order
y x1 x2 ... xJ w1 w2 ... wM T
where y is the outcome variable
      x are the covariates
      w are the confounders
      T (Poisson and Binomial models only). In the Poisson model T is the offset. 
	y~Poisson(mu), 
	log(mu) = theta  + beta%*%W + log(T) 
	(must be 1 if no offset)
	In the Binomial model, T is the total number of trials.
	T should not be present for other response models. 		

Missing covariates should be denoted with the value -999. There is currently no 
handling of missing confounders or missing offset. Please note, that even if 
--excludeY is passed, the program expects a response in each row (and also the 
offset or total number of trials if the yModel is Poisson or Binomial). In other
words, please prepare the input file as if you were going to be including Y in 
the fit. It is fine (and proper if the yModel is Poisson or Binomial) to pass 
both --yModel=... and --excludeY arguments as the --yModel helps determine how 
the data is read, but will be ignored in terms of fitting if the --excludeY 
argument is present.

An example input file for binary outcome and categorical data is given in 
	data/input/example_binary_discrete_input.txt
An example input file for Poisson outcome and categorical data is given in
	data/input/example_Poisson_discrete_input.txt
An example input file for Poisson outcome and Normal data is given in
	data/input/example_Poisson_Normal_input.txt

We recommend you store real data outside the data directory in this package to 
avoid it being overwritten when the package is updated.

### Hyperparameters: ###

Hyperparameters for the priors can be specified in an input file which is passed 
at command line using the --hyper option. Each row in this file should 
correspond to a different hyper parameter and should be in the format

parameter1=value1
parameter2=value2

Where the parameter is a vector or matrix, the elements should be all on the 
same line separated by spaces. The user can specify some or all hyperparameters. 
Those hyperparameters not specified will take their default values. Where the 
file is not provided, all hyperparameters will take their default values.

An example parameter file is provided in
	data/input/example_hyperparameter_file.txt

The possible hyperparameters are (with definition):
rAlpha  		- The shape parameter for Gamma prior on alpha 
			  (default=1.0)
sAlpha  		- The inverse-scale (rate) parameter for the Gamma prior
			  on alpha (default=0.5)
useReciprocalNCatsPhi 	- Boolean denoting whether the vector phi_j (for 
			  covariate j) have all elements equal (only used in the 
			  discrete covariate case, default=true)
aPhi			- The vector of parameters for the Dirichlet prior on 
			  phi_j. Element j corresponds to covariate j which then
			  has a prior Dirichlet(aPhi[j],aPhi[j],....,aPhi[j]). 
			  (Only used in discrete case if useReciprocalNCatsPhi 
			  is false, default=(1 1 1 ... 1))   
aDelta			- The value of delta_0 for ordinal covariates (only used
			  in the discrete case for ordinal covariates, 
			  default=-7.5)
bDelta			- The value of delta_NCat for ordinal covariates (only 
			  used in the discrete case for ordinal covariates, 
			  default=7.5) 
mu0			- The mean vector for mu_c in the Normal covariate case 
			  (only used in Normal covariate case, default=empirical 
			  covariate means)
Tau0			- The precision matrix for mu_c in the Normal covariate 
			  case (only used in Normal covariate case, 
                          default=inverse of diagonal matrix with elements equal 
                          to square of empirical range for each covariate) 
R0			- The matrix parameter for the Wishart distribution for 
			  Tau_c (only used in Normal covariate case, 
                          default=1/nCovariates * inverse of empirical 
                          covariance matrix)
kapp0			- The degrees of freedom parameter for the Wishart 
                          distribution for Tau_c (only used in Normal covariate 
                          case, default=nCovariates).
muTheta			- The location parameter for the t-Distribution for 
                          theta_c (only used if response included in model, 
                          default=0)
sigmaTheta		- The scale parameter for the t-Distribution for 
			  theta_c (only used if response included in model, 
			  default=2.5)
dofTheta		- The dof parameter for the t-Distribution for theta_c 
                          (only used if response included in model, default=7)
muBeta			- The location parameter for the t-Distribution for beta 
                          (only used when confounders present, default=0)
sigmaBeta		- The scale parameter for the t-Distribution for beta 
                          (only used when confouunders present, default=2.5)
dofBeta			- The dof parameter for the t-Distribution for beta 
                          (only used when confounders present, default=7)
aEpsilon		- Shape parameter for gamma distribution for prior for 
			  precision tau of extra variation errors epsilon (only 
                          used if extra variation is used i.e. --extraYVar flag 
   			  is included, default=5.0)
bEpsilon		- Inverse-scale (rate) parameter for gamma distribution 
			  for prior for precision tau of extra variation errors 
			  epsilon (only used if extra variation is used i.e. 
			  --extraYVar flag is used, default=0.5)
aRho                    - Parameter for beta distribution for prior on rho in 
			  variable selection (default=0.5)
bRho                    - Parameter for beta distribution for prior on rho in 
			  variable selection (default=0.5)

 
### Predictions (at C++ run time) ###

The algorithm can now take an input file of predictive scenarios. The first line
in this file must contain the number of predictive subjects, and then subsequent 
lines must have the covariate values for each of these subjects. An example file 
is in example_Normal_predictX.txt in the data/input folder.

At each iteration the predictive subjects are assigned to one of the current 
clusters according to their covariate profiles (but ignoring missing values), or
their Rao Blackwellised estimate of theta is recorded (a weighted average of all
theta, weighted by the probability of allocation into each cluster. 

The predictive subjects have no impact on the likelihood and so do not determine 
the clustering or parameters at each iteration. The predictive allocations are 
then recorded as extra entries in each row of the output_z.txt file. This can 
then be processed in the R post processing to create a dissimilarity matrix with 
the fitting subjects. The R post procesing function calcPredictions will create 
predicted response values for these subjects.

### Running the program: ###  

Runnning 
>bin/DiPBaCpp --help
will give a summary of all the possible user run time options

An example call of the C++ program (from the main folder)
>bin/DiPBaCpp --input=data/input/example_Poisson_Normal_input.txt 
 --output=data/output/output_example --nSweeps=10000 --nBurn=1000 
 --yModel=Poisson --xModel=Normal --extraYVar 
 --hyper=data/input/example_hyperparameter_file.txt 
 --predict=data/input/example_Poisson_Normal_predictX.txt


### Output and post processing: ###

Once the C++ has completed the output from fitting the regression is stored in a 
number of text files in the directory specified (in the above call the directory 
is data/output and the file stem is output_example). Files are produced 
containing the MCMC traces for all of the values of interest, along with a log 
file and files for monitoring the acceptance rates of the adaptive Metropolis 
Hastings moves. 

To produce a graphical summary of the output there is the associated
R package in the rfiles subdirectory.

The package depends on the Rcpp, clue, cluster and ggplot2 packages (available 
from CRAN)

To install the package from the rfiles subdirectory use
>R CMD INSTALL DiPBaC_1.0.0.tar.gz

Then in R the commands are:
>require(DiPBaC)
>runInfoObj<-readRunInfo('../data/output','output_example')
>dissimObj<-calcDissimilarityMatrix(runInfoObj)
>clusObj<-calcOptimalClustering(dissimObj)
>riskProfileObj<-calcAvgRiskAndProfile(clusObj))
>clusterOrderObj<-plotRiskProfile(riskProfileObj,'../data/output/summary.png') 

The last two R functions take a little time. 

The summaries produced are different from those reported in the previous papers. 
In particular, all clusters are visually displayed together (this has worked 
well for my problems with the number of clusters being returned, but may need 
tweaking to split over a number of pages depending on the problem). 

For discrete covariates, instead of plotting the probability that a phi is above 
or below the mean value, we plot the actual phi values (and plot the mean value 
across clusters as a horizontal line). 

For normal covariates, for each covariate the upper plot is the posterior 
distribution for the mean mu, and the lower plot is the posterior distribution 
of sqrt(Sigma[j,j]) (i.e. the standard deviation for that covariate).    

There are also now two extra plotting functions
>plotRiskProfileRank(riskProfileObj,'../data/out/summaryRank.png')
This function produces essentially a slimmed down version of the previous plot, 
showing only the "mean" levels (through the use of a heat map) of each of the 
clusters

>plotClustering(clusObj,'../data/output/cluster.png')
This function produces a visual representation of how the subjects cluster when 
plotted against the two principal components.

There is also now an additional function calcPredictions for computing predicted 
responses, for various prediction scenarios. It is assumed that the predictive 
allocations or Rao-Blackwell predictions have already been done in C++ (using 
the --predict=<filename> run  time option). The user can provide the function 
with a file through the predictResponseFileName argument. This file has the 
number of subjects, followed by a row for each subject, where each row contains 
values for the response, confounder and offset / number of trials (depending on 
the response model) where available. Missing values in this file are denoted 
(-999). If the file is not provided then the response, confounder and offset 
data is treated as missing for all subjects. If a subject is missing confounder 
values, then the mean value or 0 category confounder is used in the predictions 
(i.e. no confounder contribution to predicted response). If the offset / number 
of trials is missing this value is taken to be 1 when making predictions. If the
response is provided for all subjects, the predicted responses are compared with
the observed responses and the bias and rmse are computed.

The function can produce predicted values based on simple allocations 
(the default), or a Rao-Blackwellised estimate of predictions, where 
the probabilities of allocations are used instead of actually performing a 
random allocation.

An example file where the observed response is missing is in 
data/input/example_Poisson_Normal_predictYW_NoObsY.txt (there are no confounders 
in this example, but these would just be added as columns between the first and 
last columns). An example of using the function, which would do the Rao 
Blackwellised predictions, is given by

>calcPredictions(riskProfileObj, 
  predictResponseFileName='../data/input_example_Poisson_Normal_predictYW_NoObsY.txt',
  doRaoBlackwell=T)

An example file where the observed response are present is in 
data/input/example_Poisson_Normal_predictYW_NoObsY.txt (there are no confounders 
in this example, but these would just be added as columns between the first and 
last columns). An example of using the function, which would do the simple 
predictions using the allocations produced by the C++, is given by

>calcPredictions(riskProfileObj,
  predictResponseFileName='../data/input_example_Poisson_Normal_predictYW_NoObsY.txt',
  doRaoBlackwell=F)

In order to support variable selection runs, the plotRiskProfile and 
plotRiskProfileRank functions have an argument useProfileStar (by default false) 
which, if true, will use the composite phi (the mixture between phi and the null 
phi) or composite mu (the mixture between mu and null mu) in the plots. It is 
also possible to use the whichCovariates argument to restrict which covariates 
are plotted. There is also the function summariseVarSelectRho for summarising 
the continuous switches in variable selection runs.

There is additionally some extra functions for computing the divergence between 
two separate profile regressions runs. This work is joint work with Georgios 
Papageorgiou and is work in progress. We are currently performing simulations to 
understand how this measure works and will provide further notes in later 
releases. 
   
